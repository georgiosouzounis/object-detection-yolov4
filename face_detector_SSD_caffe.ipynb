{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_detector_SSD_caffe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2lhJGlUolg"
      },
      "source": [
        "# Face Detection using SSD and the Caffe pre-trained model\n",
        "\n",
        "*by Georgios K. Ouzounis, June 21st, 2021*\n",
        "\n",
        "This notebook demonstrates face detection in still images using the SSD detector configured with the Caffe pretrained model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhWwBRmakX3R"
      },
      "source": [
        "## Copy the model files\n",
        "\n",
        "We need the configuration file and the pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbKHfgpWWzj"
      },
      "source": [
        "%mkdir model/\n",
        "%cd model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6CqVH9HXsuJ"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/georgiosouzounis/face-detection-ssd-caffe/main/model/deploy.prototxt.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgcbX_0tYWGB"
      },
      "source": [
        "!wget https://github.com/georgiosouzounis/face-detection-ssd-caffe/raw/main/model/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz_dS44dftRL"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok5tWU5u6all"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt_oDhct6oy5"
      },
      "source": [
        "# import the relevant libraries\n",
        "import numpy as np\n",
        "import cv2 # openCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeeRXO2aVEcd"
      },
      "source": [
        "# check the opencv version\n",
        "if cv2.__version__ < '4.5.2':\n",
        "  print(\"opencv version: \", cv2.__version__)\n",
        "  print(\"please upgrade your opencv installation to the latest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WltH7moJZLUN"
      },
      "source": [
        "# if the openCV version is < 4.4.0 update to the latest otherwise skip this step\n",
        "!pip install opencv-python==4.5.2.52"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8GGbOIU6lwN"
      },
      "source": [
        "## Read the model and initialize the detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owV7y9stVIVq"
      },
      "source": [
        "# load the serialized model from the local copy in model/\n",
        "model_cfg = \"model/deploy.prototxt.txt\"\n",
        "model_weights = \"model/res10_300x300_ssd_iter_140000.caffemodel\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxTyPL41lIq3"
      },
      "source": [
        "# read the model\n",
        "detector = cv2.dnn.readNetFromCaffe(model_cfg, model_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCwOThbBlSEX"
      },
      "source": [
        "## Get a test image\n",
        "\n",
        "Set the path to an image containing a face in your own Google Drive or use the example as shown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhyDVnJrdIU4"
      },
      "source": [
        "%cp /content/drive/MyDrive/object_detection/macron.jpg ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0M2RO74dgaE"
      },
      "source": [
        "test_img = \"macron.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvhdDMDzY90c"
      },
      "source": [
        "# load the test image and create an image blob\n",
        "image = cv2.imread(test_img)\n",
        "(h, w) = image.shape[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcd-IbTRg0oc"
      },
      "source": [
        "# display the image \n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGC5q3q560V3"
      },
      "source": [
        "## Deploy the detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t82dGX97aZ1t"
      },
      "source": [
        "# set the intensity scaling factor; 1 in this case, i.e. original image intensities\n",
        "scalefactor = 1.0\n",
        "# set the new dimensions for image resizing to match the network requirements\n",
        "new_size = (300, 300)\n",
        "\n",
        "# create a blob using OpenCV's DNN functionality and by performing mean subtraction \n",
        "# to normalize the input\n",
        "blob = cv2.dnn.blobFromImage(image, scalefactor, new_size, (127.5, 127.5, 127.5), swapRB=True, crop=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcQ2yPZdtXP"
      },
      "source": [
        "# set the blob as input to the network\n",
        "detector.setInput(blob)\n",
        "# compute the forward pass - detect faces if any\n",
        "detections = detector.forward()\n",
        "detections.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL-87zOo7Dh7"
      },
      "source": [
        "## Analyze the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XnDTQiGqzmK"
      },
      "source": [
        "Let us review the detections. The shape of the detections is expected to be in the following format: ```[1, 1, N, 7]```, where N is the number of detected bounding boxes. For each detection, the description has the format: ```[image_id, label, conf, x_min, y_min, x_max, y_max]```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjpkDirv4fn"
      },
      "source": [
        "detections[0][0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtnLhOdDmg64"
      },
      "source": [
        "len(detections[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZmFqPz8eKwJ"
      },
      "source": [
        "# set the confidence threshold\n",
        "confidence_threshold = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ6f8eM2eCd-"
      },
      "source": [
        "# loop over the detections\n",
        "for i in range(0, detections.shape[2]):\n",
        "  # extract the confidence (i.e., probability) associated with the prediction\n",
        "  confidence = detections[0, 0, i, 2]\n",
        "  # ignore weak detections\n",
        "  if confidence > confidence_threshold:\n",
        "    # compute the (x, y)-coordinates of the bounding box for the detected object\n",
        "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "    # draw the bounding box of the detected face\n",
        "    cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "    # print the probability of this detection\n",
        "    text = \"confidence: {:.2f}%\".format(confidence * 100)\n",
        "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "    cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrcEBUfeU9o"
      },
      "source": [
        "# show the output image\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AmjzNHP-REi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}